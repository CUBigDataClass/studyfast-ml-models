{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling Experiments\n",
    "\n",
    "Several experiments in topic modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "import math\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup and seed both numpy and nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/carlcortright/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1337)\n",
    "nltk.download('wordnet')\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils\n",
    "\n",
    "A bunch of utils for cleaning and pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucket_times(data, seconds=30):\n",
    "    buckets = {}\n",
    "    for timeframe in data:\n",
    "        bucket = math.floor(timeframe['start']/seconds)\n",
    "        buckets[bucket] = buckets.get(bucket, \"\") + timeframe['text'] + \" \"\n",
    "    formatted = []\n",
    "    for k, v in buckets.items():\n",
    "        formatted.append({'bucket': k, 'text': v})\n",
    "    return formatted\n",
    "\n",
    "def json_file_to_pd(filepath):\n",
    "    f = open(filepath, 'r')\n",
    "    data = json.load(f)\n",
    "    data = bucket_times(data)\n",
    "    df = pd.DataFrame.from_dict(json_normalize(data), orient='columns')\n",
    "    return df\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucket</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>this next problem is a bit of a classic and I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>they say 24 inches square so it is 24 by 24 sq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>equal size square there and then it cut an equ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>should I cut out in order to maximize the volu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>the base and what are the dimensions of the ba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bucket                                               text\n",
       "0       0  this next problem is a bit of a classic and I'...\n",
       "1       1  they say 24 inches square so it is 24 by 24 sq...\n",
       "2       2  equal size square there and then it cut an equ...\n",
       "3       3  should I cut out in order to maximize the volu...\n",
       "4       4  the base and what are the dimensions of the ba..."
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = json_file_to_pd('test.json')\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['they', 'say', '24', 'inches', 'square', 'so', 'it', 'is', '24', 'by', '24', 'square', 'by', 'cutting', 'equal', 'squares', 'from', 'the', 'corners', 'and', 'turning', 'up', 'the', 'sides', 'so', 'what', 'are', 'they', 'saying', 'well', \"they're\", 'say', \"we're\", 'going', 'to', 'cut', 'equal', 'squares', 'from', 'the', 'corner', 'so', \"let's\", 'say', 'we', 'cut', 'a', 'and', 'let', 'me', 'see', 'if', 'I', 'can', 'draw', 'this', 'well', 'so', \"I'm\", 'going', 'to', 'cut', 'a', 'square', 'here', 'and', \"I'm\", 'going', 'to', 'cut', 'an', 'equal', 'size', 'square', 'there', 'I', 'want', 'to', 'draw', 'this', 'neatly', 'and', 'then', 'I', 'cut', 'it', '']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['inch', 'squar', 'squar', 'cut', 'equal', 'squar', 'corner', 'turn', 'side', 'say', 'go', 'equal', 'squar', 'corner', 'draw', 'go', 'squar', 'go', 'equal', 'size', 'squar', 'want', 'draw', 'neat']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = raw.loc[[1]].values[0][1]\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = raw['text'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "# count = 0\n",
    "# for k, v in dictionary.iteritems():\n",
    "#     print(k, v)\n",
    "#     count += 1\n",
    "#     if count > 10:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_doc_4310 = bow_corpus[1]\n",
    "# for i in range(len(bow_doc_4310)):\n",
    "#     print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], dictionary[bow_doc_4310[i][0]], bow_doc_4310[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot compute LDA over an empty collection (no terms)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-231-edcc843d402c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlda_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaMulticore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# for idx, topic in lda_model.print_topics(-1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     print('Topic: {} \\nWords: {}'.format(idx, topic))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mgamma_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_probability\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_word_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         )\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_terms\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot compute LDA over an empty collection (no terms)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot compute LDA over an empty collection (no terms)"
     ]
    }
   ],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=3, id2word=dictionary, passes=2, workers=2)\n",
    "# for idx, topic in lda_model.print_topics(-1):\n",
    "#     print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot compute LDA over an empty collection (no terms)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-232-a3d4b77d4d91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlda_model_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaMulticore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# for idx, topic in lda_model_tfidf.print_topics(-1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     print('Topic: {} Word: {}'.format(idx, topic))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_every\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mgamma_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimum_probability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_probability\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mminimum_phi_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_word_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mper_word_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         )\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_terms\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot compute LDA over an empty collection (no terms)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot compute LDA over an empty collection (no terms)"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=4, id2word=dictionary, passes=2, workers=4)\n",
    "# for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "#     print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "histograms = {}\n",
    "for i in range(0, len(bow_corpus)):\n",
    "    for index, score in sorted(lda_model[bow_corpus[i]], key=lambda tup: -1*tup[1]):\n",
    "        histograms[index] = histograms.get(index, list()) + [score]\n",
    "\n",
    "        \n",
    "bins = np.linspace(0, 1, len(bow_corpus))\n",
    "for topic, scores in histograms.items():\n",
    "    pyplot.hist(scores, bins, alpha=0.5, label=str(topic))\n",
    "pyplot.legend(loc='upper right')\n",
    "axes = pyplot.gca()\n",
    "axes.set_ylim([0,15])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
